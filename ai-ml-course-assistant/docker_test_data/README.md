# Docker Test Data Directory

This directory is used for Docker testing to avoid affecting production data.

## Purpose

- **Isolated testing:** Test Docker container without modifying real data
- **Safe experimentation:** Try different configurations
- **Clean state:** Easy to reset by deleting this folder

## Structure

```
docker_test_data/
‚îú‚îÄ‚îÄ chroma_db/          # ChromaDB test database (created by container)
‚îú‚îÄ‚îÄ processed/          # Processed documents (created by container)
‚îú‚îÄ‚îÄ raw/               # Raw input files (copy sample files here)
‚îî‚îÄ‚îÄ README.md          # This file
```

## Usage

### Option 1: Start with Empty Database
```bash
# Container will create empty ChromaDB
docker-compose -f docker-compose.test.yml up -d
```

### Option 2: Copy Sample Data
```bash
# Copy some sample documents for testing
Copy-Item data/raw/papers/*.pdf docker_test_data/raw/papers/ -Recurse

# Run pipeline inside container to process
docker-compose -f docker-compose.test.yml exec streamlit-test python run_pipeline.py
```

### Option 3: Copy Existing Database
```bash
# Copy entire ChromaDB for testing (WARNING: may be large)
Copy-Item data/chroma_db docker_test_data/ -Recurse
```

## Reset Test Environment

```bash
# Stop container
docker-compose -f docker-compose.test.yml down

# Delete test data
Remove-Item docker_test_data/* -Recurse -Force

# Start fresh
docker-compose -f docker-compose.test.yml up -d
```

## Production Data Safety

‚úÖ This directory is SEPARATE from `./data/`
‚úÖ Production data in `./data/` is NOT affected by Docker tests
‚úÖ Test container uses port 8502 (production uses 8501)

*python run_pipeline.py process --doc-id  realpython_python-ai-neural-network realpython_python-keras-text-classification realpython_pytorch-vs-tensorflow

*python run_pipeline.py process --doc-id   arxiv_1907_11692 arxiv_2005_11401  arxiv_1905_11946 arxiv_1906_08237

*python run_pipeline.py process --doc-id  arxiv_1608_06993 arxiv_1609_02907 arxiv_1611_05431 arxiv_1704_04861 arxiv_1707_06347   

python run_pipeline.py process --doc-id realpython_logistic-regression-python  medium_map-mrr-search-ranking medium_production-llms-nemo medium_running-evals-rag-pipeline medium_transformers-text-excel medium_vibe-proving-llms arxiv_1409_3215 arxiv_1409_4842 arxiv_1411_1784 arxiv_1502_03167 arxiv_1505_04597  

*arxiv_1703_06870 arxiv_1506_02640 arxiv_1512_03385 arxiv_1607_06450 realpython_image-processing-pillow arxiv_2001_08361


–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π 5-–µ—Ç–∞–ø–Ω–∏–π –ø–ª–∞–Ω —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É Python —Ñ–∞–π–ª—ñ–≤:

üìã –ï–¢–ê–ü 1: Fix Critical Bugs & Validation
–ú–µ—Ç–∞: –í–∏–ø—Ä–∞–≤–∏—Ç–∏ –ª–æ–≥—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏, —è–∫—ñ —Å–ø–æ—Ç–≤–æ—Ä—é—é—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

–©–æ —à—É–∫–∞—Ç–∏:

‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ —É–º–æ–≤–∏ (edge cases: –ø–æ—Ä–æ–∂–Ω—ñ —Å–ø–∏—Å–∫–∏, None, zero division)
‚ùå –õ–æ–≥—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ –≤ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è—Ö (metrics –∑–∞–≤–∂–¥–∏ 1.0/0.0)
‚ùå –í—ñ–¥—Å—É—Ç–Ω—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ—Ä–æ–∂–Ω—ñ—Ö –∫–æ–ª–µ–∫—Ü—ñ–π
–ü—Ä–∏–∫–ª–∞–¥ —Ñ—ñ–∫—Å—ñ–≤:
# ‚ùå BEFORE: Image hit rate –∑–∞–≤–∂–¥–∏ 1.0
if expected_images > 0:
    return len(retrieved_images) > 0  # Wrong: bool ‚Üí 1.0

# ‚úÖ AFTER: –ü—Ä–∞–≤–∏–ª—å–Ω–∏–π recall
if expected_images > 0:
    return len(set(retrieved) & set(expected)) / len(expected)
 üìã –ï–¢–ê–ü 2: Exception Handling & Constants
–ú–µ—Ç–∞: –ó—Ä–æ–±–∏—Ç–∏ –∫–æ–¥ —Å—Ç—ñ–π–∫–∏–º –¥–æ –ø–æ–º–∏–ª–æ–∫ —Ç–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞–±–µ–ª—å–Ω–∏–º

–©–æ —à—É–∫–∞—Ç–∏:

‚ùå File I/O –±–µ–∑ try-except (read/write files)
‚ùå API calls –±–µ–∑ error handling
‚ùå Hard-coded magic numbers (0.7, 0.5, 10)
‚ùå Hard-coded paths ("data/results.json")
–©–æ —Ä–æ–±–∏—Ç–∏:
# ‚ùå BEFORE: Magic numbers
if recall > 0.7 and mrr > 0.5:
    k_text = 10

# ‚úÖ AFTER: Named constants
TARGET_RECALL = 0.7
TARGET_MRR = 0.5
DEFAULT_K_TEXT = 10

if recall > TARGET_RECALL and mrr > TARGET_MRR:
    k_text = DEFAULT_K_TEXT
File I/O pattern:
  try:
    with open(path, 'r') as f:
        data = json.load(f)
except FileNotFoundError:
    raise FileNotFoundError(f"File not found: {path}")
except json.JSONDecodeError as e:
    raise ValueError(f"Invalid JSON: {e}")
     
–ï–¢–ê–ü 3: SOLID Principles (SRP, DRY, KISS)
–ú–µ—Ç–∞: –°–ø—Ä–æ—Å—Ç–∏—Ç–∏ –∫–æ–¥, –≤–∏–¥–∞–ª–∏—Ç–∏ –¥—É–±–ª—é–≤–∞–Ω–Ω—è

Single Responsibility Principle:

# ‚ùå BEFORE: –û–¥–∏–Ω –º–µ—Ç–æ–¥ —Ä–æ–±–∏—Ç—å 5 —Ä–µ—á–µ–π
def evaluate_query(query):
    # 1. Retrieval
    chunks = retriever.retrieve(query)
    # 2. Extract IDs
    doc_ids = [c.metadata['doc_id'] for c in chunks]
    # 3. Compute metrics
    recall = calc_recall(doc_ids, relevant)
    # 4. Log results
    print(f"Recall: {recall}")
    # 5. Return metrics
    return {'recall': recall}

# ‚úÖ AFTER: –†–æ–∑–±–∏—Ç–∏ –Ω–∞ –æ–∫—Ä–µ–º—ñ –º–µ—Ç–æ–¥–∏
def evaluate_query(query):
    chunks = self._perform_retrieval(query)
    doc_ids = self._extract_ids(chunks)
    metrics = self._compute_metrics(doc_ids)
    self._log_results(metrics)
    return metrics

 Don't Repeat Yourself:
 # ‚ùå BEFORE: –î—É–±–ª—é–≤–∞–Ω–Ω—è –∫–æ–¥—É
avg_recall = sum(recalls) / len(recalls)
min_recall = min(recalls)
max_recall = max(recalls)

avg_precision = sum(precisions) / len(precisions)
min_precision = min(precisions)
max_precision = max(precisions)

# ‚úÖ AFTER: DRY helper
def _aggregate_metric(values):
    return {
        'avg': sum(values) / len(values),
        'min': min(values),
        'max': max(values)
    }

recall_stats = _aggregate_metric(recalls)
precision_stats = _aggregate_metric(precisions)

Keep It Simple, Stupid:

–†–æ–∑–±–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –Ω–∞ –ø—Ä–æ—Å—Ç—ñ
–£–Ω–∏–∫–∞—Ç–∏ –≤–∫–ª–∞–¥–µ–Ω–∏—Ö —Ü–∏–∫–ª—ñ–≤ >2 —Ä—ñ–≤–Ω—ñ–≤
–ü–µ—Ä–µ–ø–∏—Å–∞—Ç–∏ –∑–∞–ø–ª—É—Ç–∞–Ω—É –ª–æ–≥—ñ–∫—É
üìã –ï–¢–ê–ü 4: Dataclasses for Type Safety
–ú–µ—Ç–∞: –ó–∞–º—ñ–Ω–∏—Ç–∏ Dict/Tuple –Ω–∞ —Ç–∏–ø—ñ–∑–æ–≤–∞–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏

–ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ dataclass:
‚úÖ –ú–µ—Ç—Ä–∏–∫–∏/—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ –±–∞–≥–∞—Ç—å–º–∞ –ø–æ–ª—è–º–∏
‚úÖ –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è JSON serialization
‚ùå –ü—Ä–æ—Å—Ç—ñ key-value –ø–∞—Ä–∏ (–¥–æ—Å—Ç–∞—Ç–Ω—å–æ Dict)
Pattern:
# ‚ùå BEFORE: Dict hell
result = {
    'recall': 0.85,
    'precision': 0.72,
    'mrr': 0.64,
    'query_id': 1,
    'query': "what is CNN"
}

# ‚úÖ AFTER: Type-safe dataclass
@dataclass
class QueryMetrics:
    query_id: int
    query: str
    recall: float
    precision: float
    mrr: float
    
    def to_dict(self) -> dict:
        return asdict(self)
 –ï–¢–ê–ü 5: Dependency Injection & Configurability
–ú–µ—Ç–∞: –ó—Ä–æ–±–∏—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑–∞–º—ñ–Ω–Ω–∏–º–∏ —Ç–∞ —Ç–µ—Å—Ç–æ–≤–∞–Ω–∏–º–∏

Pattern:

# ‚ùå BEFORE: Hard-coded dependencies
class Evaluator:
    def __init__(self):
        self.retriever = MultimodalRetriever()  # Hard-coded
        self.output_dir = "results/"            # Hard-coded

# ‚úÖ AFTER: Dependency Injection
class Evaluator:
    def __init__(
        self, 
        retriever: MultimodalRetriever = None,
        output_dir: str = DEFAULT_OUTPUT_DIR
    ):
        self.retriever = retriever or MultimodalRetriever()
        self.output_dir = Path(output_dir)
 –ë–û–ù–£–°: Rounding & Formatting
–ú–µ—Ç–∞: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å –≤–∏–≤–µ–¥–µ–Ω–Ω—è
recall = round(recall, 2)
precision = round(precision, 2)
‚ñ° –ï–¢–ê–ü 1: Critical Bugs
  ‚ñ° Edge cases (empty lists, None, zero division)
  ‚ñ° –õ–æ–≥—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ –≤ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è—Ö
  ‚ñ° –í–∞–ª—ñ–¥–∞—Ü—ñ—è –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö

‚ñ° –ï–¢–ê–ü 2: Exception Handling
  ‚ñ° Try-catch –¥–ª—è File I/O
  ‚ñ° Try-catch –¥–ª—è API calls
  ‚ñ° Magic numbers ‚Üí Constants
  ‚ñ° Hard-coded paths ‚Üí Configurable

‚ñ° –ï–¢–ê–ü 3: SOLID
  ‚ñ° SRP: –†–æ–∑–±–∏—Ç–∏ –≤–µ–ª–∏–∫—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
  ‚ñ° DRY: –í–∏–¥–∞–ª–∏—Ç–∏ –¥—É–±–ª—é–≤–∞–Ω–Ω—è
  ‚ñ° KISS: –°–ø—Ä–æ—Å—Ç–∏—Ç–∏ —Å–∫–ª–∞–¥–Ω—É –ª–æ–≥—ñ–∫—É

‚ñ° –ï–¢–ê–ü 4: Dataclasses
  ‚ñ° Metrics ‚Üí @dataclass
  ‚ñ° Config ‚Üí @dataclass
  ‚ñ° Results ‚Üí @dataclass

‚ñ° –ï–¢–ê–ü 5: Dependency Injection
  ‚ñ° Configurable paths
  ‚ñ° Injectable dependencies
  ‚ñ° Default values

‚ñ° –ë–û–ù–£–°: Formatting
  ‚ñ° Rounding –¥–æ 2-3 –∑–Ω–∞–∫—ñ–≤
  ‚ñ° –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–µ –≤–∏–≤–µ–¥–µ–Ω–Ω—è