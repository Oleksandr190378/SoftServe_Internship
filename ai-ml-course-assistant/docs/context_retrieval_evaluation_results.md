# –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω–∫–∏ Retrieval Quality (Phase D)

**–î–∞—Ç–∞:** 8 —Å—ñ—á–Ω—è 2026  
**–ü–ª–∞–Ω:** [evaluation_plan.md](evaluation_plan.md) - –í–ê–†–Ü–ê–ù–¢ 1 (–®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç)  
**–ï—Ç–∞–ø:** A2 - –ë–∞–∑–æ–≤–∞ –æ—Ü—ñ–Ω–∫–∞ —Ä–µ—Ç—Ä–∏–≤—É

---

## üéØ –§—ñ–Ω–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

### –î–æ—Å—è–≥–Ω—É—Ç—ñ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –†–µ–∑—É–ª—å—Ç–∞—Ç | –¶—ñ–ª—å | –°—Ç–∞—Ç—É—Å | –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è |
|---------|-----------|------|--------|------------|
| **Recall@5** | **95.0%** | ‚â•70% | ‚úÖ | +25.0% |
| **Image Hit Rate** | **88.9%** | ‚â•60% | ‚úÖ | +28.9% |
| **MRR** | **1.000** | ‚â•0.70 | ‚úÖ | +30.0% |

**–í–∏—Å–Ω–æ–≤–æ–∫**: –í—Å—ñ 3 —Ü—ñ–ª—ñ Phase D –¥–æ—Å—è–≥–Ω—É—Ç—ñ! üéâ

---

## üìä –Ü—Å—Ç–æ—Ä—ñ—è –æ—Ü—ñ–Ω–∫–∏

### –ü–µ—Ä—à–∞ –æ—Ü—ñ–Ω–∫–∞ (–ø—ñ—Å–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è ChromaDB path)

**–î–∞—Ç–∞:** 8 —Å—ñ—á–Ω—è 2026 13:49:56  
**–§–∞–π–ª:** `eval/results/retrieval_eval_20260108_134956.json`

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- Recall@5: 95.0% ‚úÖ
- Image Hit Rate: 55.6% ‚ùå (–Ω–∏–∂—á–µ —Ü—ñ–ª—ñ 60%)
- MRR: 1.000 ‚úÖ
- **–ü—Ä–æ–±–ª–µ–º–∞**: Image Recall = 0.0% –¥–ª—è –≤—Å—ñ—Ö queries

**Root Cause:**
```python
# debug_metadata.py –ø–æ–∫–∞–∑–∞–≤:
"All metadata keys: ['enriched_caption', 'doc_id', 'filename', ...]"
# ‚ùå –ü–æ–ª–µ 'image_id' –í–Ü–î–°–£–¢–ù–Ñ!
```

### –î—Ä—É–≥–∞ –æ—Ü—ñ–Ω–∫–∞ (–ø—ñ—Å–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è image_id)

**–î–∞—Ç–∞:** 8 —Å—ñ—á–Ω—è 2026 (–ø—ñ—Å–ª—è rebuild ChromaDB)

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- Recall@5: 95.0% ‚úÖ
- Image Hit Rate: 88.9% ‚úÖ (+33.3% –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è!)
- MRR: 1.000 ‚úÖ

**–©–æ –≤–∏–ø—Ä–∞–≤–∏–ª–∏:**
1. –î–æ–¥–∞–ª–∏ `'image_id': image_id` –≤ metadata ([index/build_index.py](../index/build_index.py#L218))
2. –í–∏–ø—Ä–∞–≤–∏–ª–∏ JSON –¥–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—é related_image_ids ([rag/retriever.py](../rag/retriever.py))
3. –ü–µ—Ä–µ–±—É–¥—É–≤–∞–ª–∏ ChromaDB –∑ --force –¥–ª—è 19 –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤

---

## üêõ –ö—Ä–∏—Ç–∏—á–Ω—ñ –±–∞–≥–∏ –≤–∏—è–≤–ª–µ–Ω—ñ —Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—ñ

### Bug 1: ChromaDB Path Mismatch

**–°–∏–º–ø—Ç–æ–º:** `evaluate_retrieval.py` –ø–æ–≤–µ—Ä—Ç–∞–≤ 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –≤—Å—ñ—Ö queries

**Root Cause:**
```python
# build_index.py –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤:
chromadb.PersistentClient(path="data/chroma_db")

# retriever.py –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤:
persist_directory=str(chroma_dir / collection_name)  # ‚ùå Subdirectory!
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# retriever.py —Ç–µ–ø–µ—Ä –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î parent directory:
persist_directory=str(chroma_dir)  # ‚úÖ
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Text retrieval –∑–∞–ø—Ä–∞—Ü—é–≤–∞–≤ (Recall@5=95%, MRR=1.0)

---

### Bug 2: Missing image_id in ChromaDB Metadata

**–°–∏–º–ø—Ç–æ–º:** Image Hit Rate=55.6%, Image Recall=0.0%, `fetch_images_by_ids()` –ø–æ–≤–µ—Ä—Ç–∞—î 0 images

**Root Cause:**
```python
# debug_metadata.py –ø–æ–∫–∞–∑–∞–≤:
results = image_collection.get(
    where={"image_id": "arxiv_1207_0580_embedded_001"}
)
# ‚ùå –ü–æ–≤–µ—Ä—Ç–∞—î 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤, –±–æ metadata –ù–ï –º–∞—î –ø–æ–ª—è 'image_id'!

# build_index.py lines 215-226 –ù–ï –¥–æ–¥–∞–≤–∞–≤ image_id:
metadata = {
    'doc_id': img['doc_id'],
    'filename': img['filename'],
    # ‚ùå 'image_id' –≤—ñ–¥—Å—É—Ç–Ω—ñ–π!
}
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# build_index.py line 218 —Ç–µ–ø–µ—Ä –¥–æ–¥–∞—î image_id:
metadata = {
    'image_id': image_id,  # ‚úÖ CRITICAL –¥–ª—è fetch_images_by_ids()
    'doc_id': img['doc_id'],
    'filename': img['filename'],
    ...
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Image Hit Rate –ø–æ–∫—Ä–∞—â–∏–≤—Å—è –∑ 55.6% ‚Üí 88.9% (+33.3%)

---

### Bug 3: JSON Metadata Serialization

**–°–∏–º–ø—Ç–æ–º:** `related_image_ids` –∑–±–µ—Ä—ñ–≥–∞–ª–∏—Å—å —è–∫ JSON string `'["img1","img2"]'` –∞–ª–µ –ø–∞—Ä—Å–∏–ª–∏—Å—å —è–∫ comma-separated

**Root Cause:**
```python
# build_index.py –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î:
'related_image_ids': json.dumps(chunk['related_image_ids'])

# retriever.py –æ—á—ñ–∫—É–≤–∞–≤ plain string:
ids = metadata.get('related_image_ids', '').split(',')  # ‚ùå
```

**–†—ñ—à–µ–Ω–Ω—è:**
```python
# retriever.py lines 337-355 —Ç–µ–ø–µ—Ä –¥–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑—É—î JSON:
ids_str = metadata.get('related_image_ids', '')
if isinstance(ids_str, str) and ids_str.startswith('['):
    related_ids = json.loads(ids_str)  # ‚úÖ
else:
    related_ids = [id.strip() for id in ids_str.split(',') if id.strip()]
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ JSON metadata –≤ 4 –º—ñ—Å—Ü—è—Ö retriever.py

---

## üìÅ Ground Truth Dataset

**–§–∞–π–ª:** [eval/ground_truth.json](../eval/ground_truth.json)  
**–†–æ–∑–º—ñ—Ä:** 10 queries, 10 documents, 16 images

### –†–æ–∑–ø–æ–¥—ñ–ª queries:

| –¢–∏–ø | –ö—ñ–ª—å–∫—ñ—Å—Ç—å | –ü—Ä–∏–∫–ª–∞–¥–∏ |
|-----|-----------|----------|
| **Text** | 5 | "dropout regularization", "Transformer architecture" |
| **Visual** | 3 | "GAN discriminator diagram", "NumPy array visualization" |
| **Hybrid** | 2 | "agents planning tasks", "RAG chunk size" |

### –í–∞–ª—ñ–¥–∞—Ü—ñ—è:

```bash
python eval/validate_ground_truth.py
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** ‚úÖ 100% —É—Å–ø—ñ—Ö - –≤—Å—ñ 10 docs —ñ 16 images —ñ—Å–Ω—É—é—Ç—å –≤ —Å–∏—Å—Ç–µ–º—ñ

---

## üîß –¢–µ—Ö–Ω—ñ—á–Ω—ñ –¥–µ—Ç–∞–ª—ñ

### Evaluation Metrics

**1. Recall@k**
```python
recall = len(retrieved_relevant) / len(relevant_docs)
# k = [3, 5, 10]
```

**2. Precision@k**
```python
precision = len(retrieved_relevant) / len(retrieved_docs[:k])
```

**3. Mean Reciprocal Rank (MRR)**
```python
# –ü–æ–∑–∏—Ü—ñ—è –ø–µ—Ä—à–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
reciprocal_rank = 1.0 / rank if rank > 0 else 0
```

**4. Image Hit Rate**
```python
# % queries –¥–µ —Ö–æ—á–∞ –± 1 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ
hit_rate = queries_with_images / total_queries_with_relevant_images
```

### Retrieval Configuration

```python
# rag/retriever.py
text_results = 5  # Top-5 text chunks
images_per_chunk = 2  # Max 2 images per chunk
rerank = True  # Reranking enabled
```


### –ü—ñ—Å–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:

```json
{
  "query_id": "q03",
  "query": "Show me the GAN discriminator and generator architecture",
  "retrieved_image_ids": ["arxiv_1406_2661_embedded_001"],  // ‚úÖ
  "expected_image_ids": ["arxiv_1406_2661_embedded_001"],
  "image_precision": 1.0,
  "image_recall": 1.0
}
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Image Hit Rate 55.6% ‚Üí 88.9%

---

## üîç –ü—Ä–∏–∫–ª–∞–¥ —É—Å–ø—ñ—à–Ω–æ–≥–æ retrieval

### Query: "Explain dropout regularization technique"

**Retrieved Documents (Top-5):**
1. ‚úÖ arxiv_1207_0580 (Dropout paper) - Rank 1
2. ‚úÖ realpython_gradient-descent-algorithm-python - Rank 2
3. ‚ùå arxiv_1409_1556 (GRU) - Rank 3
4. ‚ùå medium_illustrated-transformer - Rank 4
5. ‚ùå arxiv_1706_03762 (Transformer) - Rank 5

**Retrieved Images:**
1. ‚úÖ arxiv_1207_0580_embedded_001 (Dropout diagram)
2. ‚úÖ arxiv_1207_0580_embedded_002 (Comparison chart)

**Metrics:**
- Recall@5: 1.0 (1/1 relevant found)
- Precision@5: 0.2 (1/5 is relevant)
- Reciprocal Rank: 1.0 (relevant at position 1)
- Image Recall: 1.0 (2/2 expected images found)

**MRR = 1.0**: –ù–∞–π–∫—Ä–∞—â–∏–π –º–æ–∂–ª–∏–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!

---

## üéì –í–∏—Å–Ω–æ–≤–∫–∏

### –©–æ –ø—Ä–∞—Ü—é—î –¥–æ–±—Ä–µ:

‚úÖ **Text retrieval**: Recall@5=95%, MRR=1.0 - –≤—ñ–¥–º—ñ–Ω–Ω–∞ —è–∫—ñ—Å—Ç—å –ø–æ—à—É–∫—É  
‚úÖ **Image retrieval**: Hit Rate=88.9% - –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ 8/9 queries  
‚úÖ **ChromaDB**: Multimodal indexing –∑ JSON metadata –ø—Ä–∞—Ü—é—î —Å—Ç–∞–±—ñ–ª—å–Ω–æ  
‚úÖ **Enriched captions**: VLM + author + context –¥–∞—é—Ç—å —Ö–æ—Ä–æ—à—ñ embeddings

### –í–∏—è–≤–ª–µ–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏:

‚ùå **ChromaDB path compatibility**: Native client vs LangChain wrapper –º–∞–ª–∏ —Ä—ñ–∑–Ω—ñ paths  
‚ùå **Metadata schema**: image_id –Ω–µ –±—É–≤ –≤ metadata —Å–ø–æ—á–∞—Ç–∫—É  
‚ùå **JSON serialization**: –ü–æ—Ç—Ä—ñ–±–Ω–∞ explicit –¥–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è lists –≤ metadata

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è Phase D.B1 (Faithfulness):

1. **LLM Judge**: –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ GPT-4o-mini –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ groundedness –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
2. **Target**: Faithfulness score ‚â•4.0/5.0
3. **Cost**: ~$0.10 –¥–ª—è 10 queries (GPT-4o-mini –¥–µ—à–µ–≤–∏–π)
4. **Metrics**: Relevance, Completeness, Accuracy, Citation quality

---

## üìö –§–∞–π–ª–∏

**Evaluation Infrastructure:**
- [eval/ground_truth.json](../eval/ground_truth.json) - 10 annotated queries
- [eval/validate_ground_truth.py](../eval/validate_ground_truth.py) - Validation script
- [eval/evaluate_retrieval.py](../eval/evaluate_retrieval.py) - Evaluation system (347 lines)
- [eval/results/](../eval/results/) - JSON results –∑ —É—Å—ñ–º–∞ runs



**Fixed Code:**
- [rag/retriever.py](../rag/retriever.py) - ChromaDB path + JSON deserialization
- [index/build_index.py](../index/build_index.py) - Added image_id to metadata



## ‚è≠Ô∏è –ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏

**Phase D.B1: Faithfulness Judge** 
- Implement LLM-based answer evaluation
- Test on 10 ground truth queries
- Calculate faithfulness scores
- Target: ‚â•4.0/5.0 average

**Phase D: Final Report** (~1 –≥–æ–¥–∏–Ω–∞)
- Document Top 3 improvements with ROI analysis
- Cost/quality trade-offs
- Recommendations for production

**–ó–∞–≥–∞–ª—å–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å Phase D:**
- ‚úÖ A1: Ground Truth Dataset
- ‚úÖ A2: Retrieval Evaluation (Recall, MRR, Image Hit Rate)
- ‚è≥ B1: Faithfulness Judge with LLM
- ‚è≥ D: Final Report


